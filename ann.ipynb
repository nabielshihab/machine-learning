{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUTHOR:**  \n",
    "\n",
    "Nabiel Husein Shihab / nabielshihab@hotmail.com\n",
    "\n",
    "**NOTEBOOK DESCRIPTION**\n",
    "\n",
    "This notebook will show us how to perform **Artificial Neural Network (ANN)** using **Keras & Tensorflow**, including data preprocessing (encoding categorical variables, train-test splitting & feature scaling), ANN model training, predicting new dataset & evaluating the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**REFERENCES:** \n",
    "> - Chollet, F. (2018): Deep learning with Python, Manning Publication\n",
    "> - https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Brief Description About K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we use deep Learning? What is Deep Learning?\n",
    "\n",
    "Deep Learning does not require a clear understanding of the mechanism, the output only depends on the weight of the connection between the input and output systems, the value of which can be obtained from studying the training data. This method is very effective in solving fuzzy problems that have certain laws, but the mechanism is not clear. Deep learning is one part of machine learning (supervised learning model). The \"Deep\" in deep learning does not refer to any deeper understanding achieved by this approach, it actually refers to successive layers. How many layers contribute to the data model is called the depth of the model. In deep learning, these layers will be called through a model called a neural network. neural network refers to neurobiology, but although some of the central concepts in deep learning were developed in part by drawing inspiration from our understanding of the brain, there is no evidence that the brain implements anything like the learning mechanisms used in deep learning models. There are several methods included in deep learning, one of which is artificial neural networks (ANN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Does ANN Work?\n",
    "\n",
    "The information from the dataset will be entered into the network via the input neurons, which triggers the hidden neuron layers, and this will arrive at the output neurons. \n",
    "\n",
    "<img src=\"Figures/ANN_3.png\" width=\"700\"/>\n",
    "\n",
    "Not all neurons are \"triggered\" all the time. Each neuron receives input from the left neuron, and the input is multiplied by the weight of the connection it passes through. Each neuron adds up all the inputs it receives and if the sum is more than a certain threshold value, the neuron is “triggered” and triggers the neuron it is connected to (the neuron to the right of it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Does ANN \"Learn\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chollet (2018) states that the training of the ANN model revolves around the following objects:\n",
    "1. Layers, which are combined into a network or model,\n",
    "2. Appropriate input and target data,\n",
    "3. Loss function, the quantity that will be minimized during the model learning process takes place,\n",
    "4. Optimizer, determines how the model will be updated based on the loss function. Optimizer implements specific variant of stochastic gradient descent (SGD)\n",
    "\n",
    "<img src=\"Figures/ANN_4.png\" width=\"400\"/>  \n",
    "\n",
    "The image above illustrates the relationship between the four objects. The model, which consists of several layers connected to each other, maps the input data into predictions. Then the loss function will compare the prediction with the target, resulting in a loss value, a measure of how well the model prediction matches what is expected. The optimizer uses the loss value to update the weights in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TENSORFLOW & KERAS**\n",
    "\n",
    "<img src=\"Figures/tensor_flow.png\" width=\"500\"/> <img src=\"Figures/keras.png\" width=\"400\"/>\n",
    "\n",
    "we can use deep learning framework to make it easier to solve problems using deep learning. `TensorFlow is one of the frameworks for deep learning. While Keras is a library in Python that can work on the TensorFlow framework`. In simple terms Keras is the \"wrapper\" of TensorFlow. Keras is there to make it easier for us because Keras can be said to be more high-level than TensorFlow. Actually there are other frameworks that can use Keras, including Theano and CNTK. Keras was created with a focus on understanding deep learning techniques, such as creating layers for neural networks to retain concepts of shapes and mathematical details.\n",
    "\n",
    "To create a deep learning model in Keras, we can use the steps below:\n",
    "> 1. Load our dataset (*features & labels*)\n",
    "> 2. Preprocess the dataset\n",
    "> 3. Create and train ANN models\n",
    "> 4. Make predictions and evaluate the ANN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation about The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the current exercise, we will analyze customer data for a bank. Over a period of 6 months, the bank observes whether its customers leave the bank or remain. Our goal is to create an ANN that can predict, based on the geo-demographic and transactional information provided, if an individual customer will leave the bank or remain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages/Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('catalogs\\\\Churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unrelevant columns\n",
    "dataset = dataset.drop(['RowNumber', \"CustomerId\", \"Surname\"], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset\n",
    "\n",
    "In this step, we will:\n",
    "> a. Encode categorical variables  \n",
    "> b. Split dataset into train set and test set  \n",
    "> c. Rescale our feature  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorigal variables\n",
    "in our dataset, there are two attributes that are categorical variables, namely Geography and Gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding for Gender\n",
    "labelencoder_X = LabelEncoder()\n",
    "dataset['Gender'] = labelencoder_X.fit_transform(dataset['Gender'])\n",
    "\n",
    "# one hot encoding for Geography\n",
    "onehotencoder = OneHotEncoder()\n",
    "\n",
    "# creating dummy variables for Geography.\n",
    "# Reshape 1-D Geography array to 2-D because fit_transform asks 2-D \n",
    "dummy_geography = onehotencoder.fit_transform(dataset[\"Geography\"].values.reshape(-1, 1)).toarray()\n",
    "\n",
    "# combining dummy variables and our dataset \n",
    "dfOneHot = pd.DataFrame(dummy_geography, columns=[\"Geography_\"+str(int(i)) for i in range(dummy_geography.shape[1])])\n",
    "dataset = pd.concat([dfOneHot, dataset], axis=1)\n",
    "\n",
    "# remove unencoded (original) Geography\n",
    "dataset = dataset.drop(['Geography'], axis=1)\n",
    "\n",
    "# remove one of the dummy variables to avoid multicollinearity issue\n",
    "dataset = dataset.drop(['Geography_0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Splitting\n",
    "Train set will be used to train our ANN model, while test set will be used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features and labels\n",
    "X = dataset.iloc[:, 0:11].values\n",
    "y = dataset.iloc[:, 11].values\n",
    "\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "we will use standradization to rescale features, it means to substract our features with their own mean and divided by standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train ANN\n",
    "\n",
    "After we preprocess our dataset, now it's time to build our ANN model. This time, We will have 4 layers, namely: \n",
    "> a. **input layer**, consists of 11 unput units (num of features)  \n",
    "> b. **first hidden layer**, it has 6 hidden units with Relu activation function  \n",
    "> c. **second hidden layer kedua**, it has 6 hidden units with Relu activation function  \n",
    "> d. **output layer**, it has 1 output unit with Sigmoid activation function  \n",
    "\n",
    "\n",
    "<img src=\"Figures/ANN_arsitektur.png\" width=\"800\"/>\n",
    "\n",
    "\n",
    "the characteristics of our model:\n",
    "> a. There is a direct relationship between adjacent layers  \n",
    "> b. There is no direct relationship between nonadjacent layers  \n",
    "> c. There is no relationship between units in the same layer  \n",
    "> d. Using **binary crossentropy loss function** to calculate the loss score between the predicted label and the observed label during the training process  \n",
    "> e. Using **Adam optimizer** (one of the SGD methods) to update the weights  \n",
    "> f. Using batch size = 32 & epoch = 100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.5963 - accuracy: 0.7947\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4232 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.7960\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.7960\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.7960\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 0.7960\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3984 - accuracy: 0.8215\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8270\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3897 - accuracy: 0.8279\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8289\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8313\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8361\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8443\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.8447\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3716 - accuracy: 0.8472\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8494\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8490\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8500\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8509\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8535\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8535\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8533\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8540\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8568\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8536\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3585 - accuracy: 0.8549\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8580\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8577\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8554\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8545\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8553\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8577\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8555\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8551\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8561\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8560\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8579\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8566\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.8559\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8581\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8572\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8565\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8589\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8585\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8586\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3490 - accuracy: 0.8577\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8610\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3484 - accuracy: 0.8581\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8594\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8597\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8576\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.8585\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8599\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8605\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3470 - accuracy: 0.8594\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8590\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8583\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8589\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8576\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3461 - accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8594\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8605\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8576\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3457 - accuracy: 0.8594\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8593\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8601\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8576\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8602\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8602\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8602\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8599\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8599\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8594\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3440 - accuracy: 0.8604\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8597\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8576\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8591\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.8587\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3440 - accuracy: 0.8609\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8590\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8594\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8601\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8602\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8611\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8606\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8614\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3434 - accuracy: 0.8601\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8593\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8611\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8602\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8589\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8599\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8609\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8606\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8616\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8615\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8614\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2387df75448>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# forming the input layer and the first hidden layer\n",
    "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim = 11))\n",
    "\n",
    "# adding second hidden layer\n",
    "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "# adding output layer\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# Compile model ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train ANN model using train set\n",
    "classifier.fit(X_train, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions and Evaluate Our ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASuklEQVR4nO3dd5RV1dnH8e+DgxFpIhZEE2kioiKKpmksiQVFJdZgTIwVe2I0vmBFY8OlyRtLEktiNxZs+GoUlagIagAxogS7EqU3gTiYCOz3j7mQARm4mLlzZ2Z/P2vdNaef58ya+5s9+5y7J1JKSJIavyblLkCSVDcMfEnKhIEvSZkw8CUpEwa+JGWiotwF1KTZ9qf5+JDqrbljri93CdJKrVNB1LTOFr4kZcLAl6RMGPiSlAkDX5IyYeBLUiYMfEnKhIEvSZkw8CUpEwa+JGXCwJekTBj4kpQJA1+SMmHgS1ImDHxJyoSBL0mZMPAlKRMGviRlwsCXpEwY+JKUCQNfkjJh4EtSJgx8ScqEgS9JmTDwJSkTBr4kZcLAl6RMGPiSlAkDX5IyYeBLUiYMfEnKhIEvSZkw8CUpEwa+JGXCwJekTBj4kpQJA1+SMmHgS1ImDHxJyoSBL0mZMPAlKRMGviRlwsCXpEwY+JKUCQNfkjJh4EtSJgx8ScqEgS9JmTDwJSkTBr4kZcLAl6RMGPgN1A2DjmTS8CsYO+TcZcvOO3E/3ht2KS/fO5CX7x3IPrt0X7buF8fuzRtDB/Hawxew57e2Wu5YTZoEL90zgAevOanO6le+7r7zdg7uuz8HHdiHu+64DYCnhj3BQQf2oec23ZjwxuvlLbARM/AbqDv/72X6nvrbLyy/7q5n+Wa/wXyz32CGjfw7AN06teOwfXZgh0Mv48BTf8c15xxOkyaxbJ/TfrgHb30wvc5qV77eeedtHnxgCHffO4QhDw1lxPPP8Y9Jk+jSpSv/e8119Npxp3KX2KgZ+A3UqHHvMWdeZVHb7r97D4YMG8e/P1/EpCmzee+jWey0TQcANt1oPXrvsjW3PvxiCauVqnzw/nts26MHzZo1o6Kigl477sTwZ56iU+fOdOjYqdzlNXolC/yI6BYRAyLi2sJrQERstfo99d84qd+ujL7vHG4YdCTrtWwGwKYbtubjaXOXbTN5xlzab9QagKvOPoTzrnmEJUtSWepVXrp06cq4V17hk0/msnDhQka+MIJp06aVu6xslCTwI2IAcC8QwOjCK4B7ImLgKvbrHxFjI2LsolkTSlFao3bzkBfofsBFfKPfYKbNms/gMw9e5fb7fmcbZsxZwKsTP6qjCpW7Tp07c8xxx3PSCcdxyonHs2W3bqzVxI6GulJRouMeB2ydUvq8+sKI+DUwARi8sp1SSjcBNwE02/40m5xraMacBcumb3loFA9dW3UTdvLMeWzWrs2ydZtu1IYpM+bRZ7dt2X+3bem9y9Z8Ze2mtGq+DrdcehTHnn9HndeufBx8yGEcfMhhAFz7m1+z8cYbl7mifJTqV+sSoP1Klm9SWKcSaLdBq2XTfb+7HX9/byoAjz83nsP22YG1m1awefu2dPnahox540MuvO5RuvS+gG59BnHUwFt5bszbhr1Kbvbs2QBMnTKF4c88xb59DihzRfkoVQv/DGB4RLwDLO0v+BrQBTitROfMyu1XHM13em3BBuu14N0nL+GSG/7Mrr22oMeWm5FSYtLUOZx+6T0ATHx/Gg8+9SqvPngeixYv4YzB99tnr7I564zTmffJJ1RUVHDu+YNo1aoVw595msGXX8LcOXM47ZQT2XLLrbjh5j+Wu9RGJ1IqzRs/IpoAXwc2LSyaDIxJKS0uZn+7dFSfzR1zfblLkFZqnQqipnWlauGTUloCvFyq40uS1oy3xyUpEwa+JGXCwJekTBj4kpQJA1+SMmHgS1ImDHxJyoSBL0mZMPAlKRMGviRlwsCXpEwY+JKUCQNfkjJh4EtSJgx8ScqEgS9JmTDwJSkTBr4kZcLAl6RMGPiSlAkDX5IyYeBLUiYMfEnKhIEvSZkw8CUpEwa+JGXCwJekTFTUtCIiFgBp6WzhaypMp5RSqxLXJkmqRTUGfkqpZV0WIkkqraK6dCJil4g4pjC9QUR0LG1ZkqTattrAj4hBwADgnMKitYG7SlmUJKn2FdPCPwg4EPgUIKU0BbC7R5IamGIC/98ppUThBm5ENC9tSZKkUigm8O+PiBuB9SLiBOAZ4ObSliVJqm01PqWzVErp6ojYC5gPdAUuTCk9XfLKJEm1arWBX/A60Iyqbp3XS1eOJKlUinlK53hgNHAwcCjwckQcW+rCJEm1q5gW/tnA9iml2QAR0RZ4EbillIVJkmpXMTdtZwMLqs0vKCyTJDUgqxpL58zC5LvAXyNiKFV9+H2B8XVQmySpFq2qS2fph6veK7yWGlq6ciRJpbKqwdMurstCJEmltdqbthGxIfA/wNbAOkuXp5S+W8K6JEm1rJibtncDbwIdgYuBD4ExJaxJklQCxQR+25TSH4HPU0rPp5SOBWzdS1IDU8xz+J8Xvk6NiD7AFGD90pUkSSqFYgL/0ohoDZwFXAe0An5e0qokSbWumMHTHitMzgP2KG05kqRSiaqh7leyIuI6/vNPzL8gpfTTUhUFMH3+5zWeWyq3Gt42Utm1a900alq3qhb+2BLUIkkqkxpb+OVmC1/1WT1920irbOEX81imJKkRMPAlKRMGviRlopj/eNU1IoZHxBuF+R4RcX7pS5Mk1aZiWvg3A+dQ+MRtSmk80K+URUmSal8xgb9uSmn0CssWlaIYSVLpFBP4syKiM4UPYUXEocDUklYlSap1xYylcypwE9AtIiYDHwA/KmlVkqRaV/QHryKiOdAkpbRgtRvXAj94pfrMD16pvvqyQysAEBEXrjAPQErpl/91ZZKkOlNMl86n1abXAfYHJpamHElSqazxWDoR8RVgWEpp95JUVGCXjuozu3RUX9X2WDrrApt9+XIkSeVQTB/+6/xnXPy1gA0B++8lqYEppg9//2rTi4DpKSU/eCVJDcwqAz8i1qKqv75bHdUjSSqRVfbhp5QWA29FxNfqqB5JUokU06XTBpgQEaOp9ohmSunAklUlSap1xQT+BSWvQpJUcsUE/n4ppQHVF0TElcDzpSlJklQKxTyHv9dKlu1b24VIkkqrxhZ+RJwMnAJ0iojx1Va1BEaVujBJUu2qcWiFiGhN1Q3bK4CB1VYtSCnNKXVhDq2g+syhFVRfrWpohTUeS6euGPiqz+rp20aq9bF0JEkNkIEvSZkw8CUpEwa+JGXCwJekTBj4kpQJA1+SMmHgS1ImDHxJyoSBL0mZMPAlKRMGviRlwsCXpEwY+JKUCQNfkjJh4EtSJgx8ScqEgS9JmTDwJSkTBr4kZcLAl6RMGPiSlAkDX5IyUVHuAlQ7Bv/yfF4cOYI2bdbn9vseAeDdt9/kV4MvobKykk02ac8Fl1xJ8xYtWLToc668dBBvvzmRxYsX0Xu/A/nRMSeU9wLUaM2YPpXLLjqXuXNmEwQHHHQoh/b7MfPnzeOi885i2tQptNukPRdf/itatmrNPXfewjNPPg7A4sWLmfTh+wwd9gKtWrcu85U0fJFSKncNKzV9/uf1s7B66m/jxtJs3XW5fNC5ywK//1E/4JSf/YKevXbi8UcfYurkyRx/8uk8/eTjjBrxLBddfjWffbaQow7vyzU33Mom7Tct70U0IPX0bVMvzZ41k9mzZtK1W3cqP/2UE446nMuuupYnHnuEVq1bc+RPjufu2//AgvnzOen0M5fbd9QLzzHkT3fwm9/fUp7iG6B2rZtGTevs0mkkeu6wI61aLd8C+ugfk9huhx0B2PHr3+L5Z58GICL4bOFCFi1axL8++xcVTZvSvHmLOq9ZeWi7wYZ07dYdgHWbN2fzjp2YOXM6o0Y8S+8+fQHo3acvI5//yxf2HT7sz3xvn/3qtN7GzMBvxDp06rzsTfTc8KeYMX0aALt/by/WadaMg/bdg8MO2It+Rx7tn8uqE1OnTOadtybSfesezJ0zm7YbbAjA+m03YO6c2ctt+9lnCxn98kh222OvcpTaKNV54EfEMatY1z8ixkbE2Dtv/UNdltUoDbzwEh5+4F6O//HhVFZ+StOmTQGYOOF1mjRZi4ef+Av3DX2S++6+nSkff1TmatXYVVZWcuHAn3P6mQNo3mL5vygjAmL5nogXX3iObXpsb2OkFpXjpu3FwK0rW5FSugm4CezDrw2bd+jEr6+/GYCPJn3ISyNHAPD0k3/mG9/emYqKprRZvy3bbteTNydOoP1mXy1nuWrEFi36nAsHnMGe+/Rh10KLvc36bZk9ayZtN9iQ2bNm0qbN+svtM/ypJ/je3nbn1KaStPAjYnwNr9eBjUtxTn3R0j+RlyxZwh233EjfQw4HYON2mzBuzGgAFi6sZMIb49m8Q8ey1anGLaXElZdcyOYdO/GDI3+ybPnOu+7Ok48PBeDJx4ey8657LFv3z38u4LVXx7LLbnt84Xj68krylE5ETAf2AeauuAp4MaXUfnXHsIW/Zi4+72xefWUM8z75hPXbtuWY/qewsLKShx+4F4Bdd9+TE087g4igsrKSwb88nw/ff49EYr8Dvs8RPz62zFfQsPiUTvHG/20cp/c/ik5dtqBJVLUxTzjlZ2y1dQ8uOvcspk+fSrt27bno8l8t67554rFHGP3SSAZddnU5S2+QVvWUTqkC/4/ArSmlkStZ96eU0g9XdwwDX/WZga/6qs4DvzYY+KrP6unbRvI5fEmSgS9J2TDwJSkTBr4kZcLAl6RMGPiSlAkDX5IyYeBLUiYMfEnKhIEvSZkw8CUpEwa+JGXCwJekTBj4kpQJA1+SMmHgS1ImDHxJyoSBL0mZMPAlKRMGviRlwsCXpEwY+JKUCQNfkjJh4EtSJgx8ScqEgS9JmTDwJSkTBr4kZcLAl6RMGPiSlAkDX5IyYeBLUiYMfEnKhIEvSZkw8CUpEwa+JGXCwJekTBj4kpQJA1+SMmHgS1ImDHxJyoSBL0mZMPAlKRMGviRlwsCXpEwY+JKUCQNfkjJh4EtSJgx8ScpEpJTKXYPqQET0TyndVO46pBX5s1l3bOHno3+5C5Bq4M9mHTHwJSkTBr4kZcLAz4d9pKqv/NmsI960laRM2MKXpEwY+JKUCQO/kYuI3hHxVkS8GxEDy12PtFRE3BIRMyLijXLXkgsDvxGLiLWA3wL7At2BIyKie3mrkpa5Dehd7iJyYuA3bl8H3k0pvZ9S+jdwL9C3zDVJAKSURgBzyl1HTgz8xm1T4KNq8x8XlknKkIEvSZkw8Bu3ycBXq81vVlgmKUMGfuM2BtgiIjpGxNpAP+DRMtckqUwM/EYspbQIOA0YBkwE7k8pTShvVVKViLgHeAnYMiI+jojjyl1TY+fQCpKUCVv4kpQJA1+SMmHgS1ImDHxJyoSBL0mZMPCVlYjYPSIeK0wfuKoRRCNivYg45Uuc46KI+EWxy1fY5raIOHQNztXB0SZVLANfjUJhZNA1klJ6NKU0eBWbrAesceBL9ZWBr3qt0IJ9MyLujoiJEfFARKxbWPdhRFwZEeOAwyJi74h4KSLGRcSQiGhR2K534RjjgIOrHfvoiLi+ML1xRDwcEa8VXt8GBgOdI+JvEXFVYbuzI2JMRIyPiIurHeu8iHg7IkYCWxZxXScUjvNaRDy49JoK9oyIsYXj7V/Yfq2IuKrauU/8b7+3yo+Br4ZgS+B3KaWtgPks3+qenVLaAXgGOB/YszA/FjgzItYBbgYOAHoB7Wo4x7XA8yml7YAdgAnAQOC9lFLPlNLZEbE3sAVVw073BHpFxK4R0YuqYSt6AvsBOxVxTQ+llHYqnG8iUP1Tph0K5+gD3FC4huOAeSmlnQrHPyEiOhZxHmmZinIXIBXho5TSqML0XcBPgasL8/cVvn6Tqn/yMioiANam6mP73YAPUkrvAETEXUD/lZzju8BRACmlxcC8iGizwjZ7F16vFuZbUPULoCXwcEqpsnCOYsYr2iYiLqWq26gFVcNfLHV/SmkJ8E5EvF+4hr2BHtX691sXzv12EeeSAANfDcOK439Un/+08DWAp1NKR1TfMCJ61mIdAVyRUrpxhXOc8SWOdRvw/ZTSaxFxNLB7tXUru94ATk8pVf/FQER0+BLnVqbs0lFD8LWI+FZh+ofAyJVs8zKwc0R0AYiI5hHRFXgT6BARnQvbHbGSfQGGAycX9l0rIloDC6hqvS81DDi22r2BTSNiI2AE8P2IaBYRLanqPlqdlsDUiGgKHLnCusMiokmh5k7AW4Vzn1zYnojoGhHNiziPtIyBr4bgLeDUiJgItAF+v+IGKaWZwNHAPRExnkJ3TkrpM6q6cB4v3LSdUcM5fgbsERGvA68A3VNKs6nqInojIq5KKT0F/Al4qbDdA0DLlNI4qrqWXgOeoGpY6tW5APgrMIqqX0rV/QMYXTjWSYVr+APwd2Bc4THMG/EvdK0hR8tUvVbosngspbRNuWuRGjpb+JKUCVv4kpQJW/iSlAkDX5IyYeBLUiYMfEnKhIEvSZn4f3j5nVrjb5kmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# making predictions using test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# setting threshold / cut off to transform probability values into binary values\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# making confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "classes = ['0', '1']\n",
    "\n",
    "# visualize confusion matrix\n",
    "ax = sns.heatmap(cm, cmap=\"Blues\", annot=True, fmt=\".0f\", xticklabels=classes, yticklabels=classes, cbar=False)\n",
    "ax.set(xlabel=\"predicted label\", ylabel=\"true label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.8555\n"
     ]
    }
   ],
   "source": [
    "# calculate model performance using accuracy\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "correct_pred = tp + tn\n",
    "wrong_pred = fp + fn\n",
    "pred_accuracy = correct_pred / (correct_pred + wrong_pred)\n",
    "\n",
    "print('model accuracy:', pred_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our simple ANN model has accuracy of 0.86. It means we have a good model when it comes to predict a new dataset. However we can increase the performance by tuning up the hyperparameters using GridSearchCV, choosing different ANN architecture, applying regularization, etc. There is still a big room for improvement! Unfortunately we will not cover how to do those things in this notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github",
   "language": "python",
   "name": "github"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
